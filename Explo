#Importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns
import sklearn
import os
import shutil
import cv2
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.metrics import confusion_matrix, classification_report
add Codeadd Markdown
#Importing all the necessary libraries for image processing
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.callbacks import EarlyStopping, Callback , ModelCheckpoint
from tensorflow.keras.metrics import Accuracy,binary_crossentropy, FalsePositives, FalseNegatives, TruePositives, TrueNegatives
from tensorflow.keras.preprocessing.image import ImageDataGenerator
add Codeadd Markdown
shutil.rmtree("../Cancer/")
shutil.rmtree("../Cancer_train/")
shutil.rmtree("../Cancer_test/")
shutil.rmtree("../Cancer_validation/")
add Codeadd Markdown
os.getcwd()
'/kaggle/working'
add Codeadd Markdown
shutil.rmtree("./Cancer/")

add Codeadd Markdown
#Loading the text file
fold_df = pd.read_csv("../input/breakhis/Folds.csv")
add Codeadd Markdown
Folds.csv

Folds.csv contains all the information about the patient images.
Folds.csv consists of the magnifying factor of the image. the exact path where the image is stores.
So, We can extract useful information from the filename.
Here Folds.csv plays major role in designing the system.
add Codeadd Markdown
#Defining the paths
img_path = "./BreaKHis_v1/"
classes = ["benign","malign"]
add Codeadd Markdown
#Renaming the column filename to path
fold_df = fold_df.rename(columns = {"filename":"path"})
#Printing the head of the file
fold_df.head(3)
fold	mag	grp	path
0	1	100	train	BreaKHis_v1/histology_slides/breast/benign/SOB...
1	1	100	train	BreaKHis_v1/histology_slides/breast/benign/SOB...
2	1	100	train	BreaKHis_v1/histology_slides/breast/benign/SOB...
add Codeadd Markdown
#One example path is printed
fold_df['path'][1]
'BreaKHis_v1/histology_slides/breast/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-002.png'
add Codeadd Markdown
Info:

From the path column we can extract the exact file name using apply and split functions on the path column.
And also the class is extracted.
add Codeadd Markdown
#Extracting the filename and label from the path column
fold_df['filename'] = fold_df['path'].apply(lambda x:x.split("/")[-1])
fold_df["label"] = fold_df['path'].apply(lambda x: x.split("/")[3])
add Codeadd Markdown
fold_df.head(3)
fold	mag	grp	path	filename	label
0	1	100	train	BreaKHis_v1/histology_slides/breast/benign/SOB...	SOB_B_A-14-22549AB-100-001.png	benign
1	1	100	train	BreaKHis_v1/histology_slides/breast/benign/SOB...	SOB_B_A-14-22549AB-100-002.png	benign
2	1	100	train	BreaKHis_v1/histology_slides/breast/benign/SOB...	SOB_B_A-14-22549AB-100-003.png	benign
add Codeadd Markdown
Creating New Directiory Cancer

The given data consists of very complex structure of folders where it stores the images.
The structure as follows:
BreaKHis_v1
histology_slides
breast
benign
SOB
Type
patient_id
40x
100x
200x
400x
malignant
SOB
Type
patient_id
40x
100x
200x
400x
To make things simple, using the exact path of the images, all the images are moved to the common folder called Cancer.
Images are renamed with their class and patient_id.
add Codeadd Markdown
#Creating new directory
os.makedirs("../Cancer/")
---------------------------------------------------------------------------
FileExistsError                           Traceback (most recent call last)
/tmp/ipykernel_382/2371280071.py in <module>
      1 #Creating new directory
----> 2 os.makedirs("../Cancer/")

/opt/conda/lib/python3.7/os.py in makedirs(name, mode, exist_ok)
    221             return
    222     try:
--> 223         mkdir(name, mode)
    224     except OSError:
    225         # Cannot rely on checking for EEXIST, since the operating system

FileExistsError: [Errno 17] File exists: '../Cancer/'
add Codeadd Markdown
#Moving all the images to one folder
for p in fold_df['path']:
    src = "../input/breakhis/BreaKHis_v1/" + p
    dest = "../Cancer/"
    #saving the files with its corresponding class and patient_id
    dest = os.path.join(dest,src.split("/")[7]+ "_" + src.split("/")[-1])
    shutil.copyfile(src,dest)    
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
/tmp/ipykernel_382/1437013078.py in <module>
      5     #saving the files with its corresponding class and patient_id
      6     dest = os.path.join(dest,src.split("/")[7]+ "_" + src.split("/")[-1])
----> 7     shutil.copyfile(src,dest)

/opt/conda/lib/python3.7/shutil.py in copyfile(src, dst, follow_symlinks)
    120         with open(src, 'rb') as fsrc:
    121             with open(dst, 'wb') as fdst:
--> 122                 copyfileobj(fsrc, fdst)
    123     return dst
    124 

/opt/conda/lib/python3.7/shutil.py in copyfileobj(fsrc, fdst, length)
     77     """copy data from file-like object fsrc to file-like object fdst"""
     78     while 1:
---> 79         buf = fsrc.read(length)
     80         if not buf:
     81             break

KeyboardInterrupt: 
add Codeadd Markdown
#Checking the len
len(os.listdir("../Cancer/"))
add Codeadd Markdown
All the images are now stores in single folder.
add Codeadd Markdown
#Creating a new data frame with labels and file names stored in single folder
fold_df['file_loc'] = fold_df['label'] + "_" + fold_df['filename']
#Encoding the class to integer
fold_df['class'] = fold_df['label'].apply(lambda x: 0 if x =='benign' else 1)
add Codeadd Markdown
#Printing the head to display the changed made
fold_df.head(3)
add Codeadd Markdown
#Lets explore the data set
plt.figure(figsize=(10,6))
sns.set(font_scale = 1.5)
sns.set_style("darkgrid")
sns.countplot(fold_df['label']);
plt.xlabel("Class")
plt.title("No of Patients Benign and Malignant");
add Codeadd Markdown
Data is Highly Imabalanced as this is the case with the real world.
Medical datas are usually imbalanced because of their nature.
add Codeadd Markdown
#Filtering the data frame to benign and malignant for visualization
benign_df = fold_df[fold_df['label'] == 'benign']
malignant_df = fold_df[fold_df['label'] == 'malignant']
add Codeadd Markdown
Benign Samples
add Codeadd Markdown
#Plotting the benign samples
plt.figure(figsize = (30,10))
for i in range(0,40):
    plt.subplot(4,10,i+1)
    img = cv2.imread("../Cancer/"+ benign_df['file_loc'][i],1)
    plt.imshow(img)

add Codeadd Markdown
Malignant Samples
add Codeadd Markdown
#Plotting the malignant samples
images = malignant_df['file_loc'].values
plt.figure(figsize = (30,10))
for i in range(0,40):
    plt.subplot(4,10,i+1)
    img = cv2.imread("../Cancer/"+ images[i],1)
    plt.imshow(img)
add Codeadd Markdown
Findings:

From the above images there is very little to no difference between malignant and benign samples.
This might be because we are not the pathologists, That's the original purpose of the detection system.
Thus it makes it easy in the absence of actual pathologists.
add Codeadd Markdown
#Creating a new data frame with the file loc as its index, label and class of the patients as its columns.
df = pd.DataFrame(os.listdir("../Cancer/"))
df = df.rename(columns = {0:'file_loc'})
df['label'] = df['file_loc'].apply(lambda x:x.split("_")[0])
df['class'] = df['label'].apply(lambda x: 0 if x =='benign' else 1)
df.set_index("file_loc",inplace=True)
add Codeadd Markdown
#Checking the data frame
df.head(2)
add Codeadd Markdown
Using the data frame, the splitting for train, test and validation is done.
10% is kept aside as the test data, and 10% as validation data.
80% is taken as the training data.
add Codeadd Markdown
#Performing the splitting
data_train_and_val, data_test = train_test_split(df, test_size = 0.1, random_state = 47)
#Traing and val
data_train, data_val = train_test_split(data_train_and_val, test_size = 0.1, random_state = 47)
add Codeadd Markdown
print("Training size :", data_train.shape)
print("Validation size :", data_val.shape)
print("Testing size :", data_test.shape)
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
/tmp/ipykernel_382/273425357.py in <module>
----> 1 print("Training size :", data_train.shape)
      2 print("Validation size :", data_val.shape)
      3 print("Testing size :", .shape)

NameError: name 'data_train' is not defineddata_test
add Codeadd Markdown
#Plotting
sns.set_style("darkgrid")
plt.figure(figsize = (20,6))
plt.subplot(1,3,1)
sns.countplot(data_train['class'])
plt.title("Training set")
plt.subplot(1,3,2)
sns.countplot(data_val['class'])
plt.title("Validation set")
plt.subplot(1,3,3)
sns.countplot(data_test['class']);
plt.title("Test set");
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
/tmp/ipykernel_382/2835669294.py in <module>
      3 plt.figure(figsize = (20,6))
      4 plt.subplot(1,3,1)
----> 5 sns.countplot(data_train['class'])
      6 plt.title("Training set")
      7 plt.subplot(1,3,2)

NameError: name 'data_train' is not defined

add Codeadd Markdown
Training , Validation and Testing data is pretty imbalanced as this is the case in the real world.
Here the validation and testing set is left as it is, because it should reflects the real world scenario.
And the training data is balanced by oversampling the minority class(Benign).
add Codeadd Markdown
#Separating the benign and malignant patients from train data
train_has_cancer = data_train[data_train['class'] == 1]
train_has_no_cancer = data_train[data_train['class'] == 0]
add Codeadd Markdown
train_has_cancer.shape
add Codeadd Markdown
train_has_no_cancer.shape
add Codeadd Markdown
#Upsampling the minority class by the size of majority class with replacement
train_has_no_cancer_upsample = resample(train_has_no_cancer, n_samples = len(train_has_cancer), 
                                     random_state = 47, replace = True)
add Codeadd Markdown
#Concatenating the upsampled minority class and the majority class
data_train = pd.concat([train_has_cancer,train_has_no_cancer_upsample])
add Codeadd Markdown
As expected the training data is balanced.
add Codeadd Markdown
sns.set_style("darkgrid")
plt.figure(figsize = (20,6))
plt.subplot(1,3,1)
sns.countplot(data_train['class'])
plt.title("Training set")
plt.subplot(1,3,2)
sns.countplot(data_val['class'])
plt.title("Validation set")
plt.subplot(1,3,3)
sns.countplot(data_test['class']);
plt.title("Test set");
add Codeadd Markdown
Creating the directory structure for Training , Validation and Testing:
add Codeadd Markdown
Earlier all the images where stored in the single directory called Cancer.
Now we are using Image data generator as part of our algorithm designing.
Image data generator expects the Images to be in the following structure:
Train
Benign
Malignant
Validation
Benign
Malignant
Testing
Benign
Malignant
Above structure is the prerequisite for the Image Data Generator to run.
add Codeadd Markdown
#Creating the directories to store images
os.makedirs("../Cancer_train")
os.makedirs("../Cancer_test")
os.makedirs("../Cancer_validation")
os.makedirs("../Cancer_train/benign")
os.makedirs("../Cancer_train/malignant")
os.makedirs("../Cancer_validation/benign")
os.makedirs("../Cancer_validation/malignant")
os.makedirs("../Cancer_test/benign")
os.makedirs("../Cancer_test/malignant")
add Codeadd Markdown
Using the above directories and the splitted data frames data_train, data_val, data_test.
We are moving the images to the corresponding directories based on the class of the image(Benign or Malignant).
add Codeadd Markdown
#Training data
i = 1
for img in data_train.index:
    if img!=".DS_Store":
        target = df.loc[img,'class']
        if target == 1:
            label = 'malignant'
        else:          
            label = 'benign'      
        src = os.path.join("../Cancer/",img)
        dest = os.path.join("../Cancer_train/",label, "image" + str(i)+".png")
        img1 = np.array(cv2.imread(src))
        cv2.imwrite(dest,img1)
        i = i+1
add Codeadd Markdown
#Validation data
for img in data_val.index:
    target = data_val.loc[img,'class']
    if target == 1:
        label = 'malignant'
    else:
        label = 'benign'
        
    src = os.path.join("../Cancer/",img)
    dest = os.path.join("../Cancer_validation/",label,img)
    shutil.copyfile(src,dest)
add Codeadd Markdown
#Testing data
for img in data_test.index:
    target = data_test.loc[img,'class']
    if target == 1:
        label = 'malignant'
    else:
        label = 'benign'
        
    src = os.path.join("../Cancer/",img)
    dest = os.path.join("../Cancer_test/",label,img)
    shutil.copyfile(src,dest)
add Codeadd Markdown
#Checking their lengths
print("Training Data:")
print(" ")
print("Benign:",len(os.listdir("../Cancer_train/benign/")))
print("Malignant::",len(os.listdir("../Cancer_train/malignant/")))
print(" ")
print("Validation Data")
print(" ")
print("Benign size:",len(os.listdir("../Cancer_validation/benign/")))
print("Malignant size :",len(os.listdir("../Cancer_validation/malignant/")))
print(" ")
print("Testing Data:")
print(" ")
print("Benign size :",len(os.listdir("../Cancer_test/benign/")))
print("Malignant size :",len(os.listdir("../Cancer_test/malignant/")))
Training Data:
 
Benign: 544
Malignant:: 2853
 
Validation Data
 
Benign size: 187
Malignant size : 327
 
Testing Data:
 
Benign size : 218
Malignant size : 353
add Codeadd Markdown
Training data is balanced.
Testing and Validation data is kept as such to reflect the real scenario.
add Codeadd Markdown
Image Data Generator
add Codeadd Markdown
Reference: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator
Generates batches of tensor image data with real-time data augmentation.
Thus CNN sees new set of images with different variation at each epoch.
One of the useful methods to prevent the model from Overfitting.
add Codeadd Markdown
#Defining Image Data Generator
datagen = ImageDataGenerator(
    rotation_range=20,
    horizontal_flip=True,
    vertical_flip=True,
    rescale=1./255,
    shear_range=0.2,
    fill_mode='nearest',
    zoom_range=0.2)
add Codeadd Markdown
Here the Image Data Generator is defined with following functions:
Random rotation by 20 degrees.
Horizontal flip.
Vertical flip.
Rescale image by its pixel value.
Randomly Zoom image by 20%.
Random shear by 20%.
add Codeadd Markdown
Flow from Directory

Earlier Image folders where created as per the prerequisite.
Here the flow_from_directory will find the number of images and their classes based on the hierarchy.
Size of the image is set to 128x128.
Batch size of 32 and class mode of binary(Benign or Malignant).
add Codeadd Markdown
#Setting up the images for image data generator
train_generation = datagen.flow_from_directory("../Cancer_train/",target_size=(128,128),batch_size = 32, class_mode="binary")
val_generation = datagen.flow_from_directory("../Cancer_validation/", target_size=(128,128), batch_size=32, class_mode="binary")
Found 3397 images belonging to 2 classes.
Found 514 images belonging to 2 classes.
add Codeadd Markdown
CNN Architecture
add Codeadd Markdown
CNN architecture is defined using Conv2D layers and Maxpooling layers.
Dropout Layers are added to randomly turn off some neurons while training to prevent from overfitting.
Flatten layer is added at the end to form Dense Layers.
relu is used as activation in all the layers and Sigmoid as the activation in the output layer.
add Codeadd Markdown
#Defining the base model
cancer_model = Sequential()
​
#First Layer
cancer_model.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (128,128,3), activation = 'relu'))
cancer_model.add(MaxPooling2D(pool_size = (2,2)))
​
#Second Layer
cancer_model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same',activation = 'relu'))
cancer_model.add(MaxPooling2D(pool_size = (2,2)))
​
#Third Layer
cancer_model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))
cancer_model.add(MaxPooling2D(pool_size = (2,2)))
cancer_model.add(Dropout(0.4))
​
#Fourth Layer
cancer_model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'relu'))
cancer_model.add(MaxPooling2D(pool_size = (2,2)))
cancer_model.add(Dropout(0.2))
​
#Flattening the layers
cancer_model.add(Flatten())
​
#Adding the dense layer
cancer_model.add(Dense(256, activation = 'relu'))
cancer_model.add(Dense(128, activation = 'relu'))
cancer_model.add(Dense(1, activation = 'sigmoid'))
​
cancer_model.summary()
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 126, 126, 32)      896       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 63, 63, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 31, 31, 128)       73856     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 15, 15, 128)       0         
_________________________________________________________________
dropout (Dropout)            (None, 15, 15, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 15, 15, 256)       295168    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 7, 256)         0         
_________________________________________________________________
flatten (Flatten)            (None, 12544)             0         
_________________________________________________________________
dense (Dense)                (None, 256)               3211520   
_________________________________________________________________
dense_1 (Dense)              (None, 128)               32896     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,632,961
Trainable params: 3,632,961
Non-trainable params: 0
_________________________________________________________________
add Codeadd Markdown
#Setting the learning rate to reduce gradually over the training period
lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(
  0.001,
  decay_steps=20*50,
  decay_rate=1,
  staircase=False)
​
def get_optimizer():
  return tf.keras.optimizers.Adam(lr_schedule)
add Codeadd Markdown
#Creating new directory to store the best model
os.makedirs("./Best_model")
add Codeadd Markdown
Model Compilation
add Codeadd Markdown
Model is compiled by using binary crossentropy as the loss function and adam optimizer to optimize the weights.
Early stopping is involved to monitor validation loss inorder to prevent overfitting with patience level = 5
Modelcheckpoint is used to store the best models for every epoch.
add Codeadd Markdown
#Compiling the model
cancer_model.compile(loss='binary_crossentropy', optimizer = get_optimizer(), metrics = ['accuracy'])
early_stop = EarlyStopping(monitor='val_loss',patience=5)
checkpoint = ModelCheckpoint("./Best_model/",save_best_only=True,)
add Codeadd Markdown
Model Fit
add Codeadd Markdown
Model is fitted using train and validation generators generated using Image DataGenerator.
Verbose is set to 1 to monitor accuracy and losses.
Model is trained for 200 epochs.
early stopping and checkpoint are used as the call backs.
add Codeadd Markdown
#Model is fitted using train and validation generator for 200 epochs
history = cancer_model.fit(train_generation, validation_data=val_generation, epochs=200 ,
                 callbacks=[early_stop,checkpoint], verbose = 1)
Epoch 1/200
107/107 [==============================] - 97s 904ms/step - loss: 0.2678 - accuracy: 0.9040 - val_loss: 0.4688 - val_accuracy: 0.8424
Epoch 2/200
107/107 [==============================] - 97s 904ms/step - loss: 0.2479 - accuracy: 0.9146 - val_loss: 0.3947 - val_accuracy: 0.8541
Epoch 3/200
107/107 [==============================] - 97s 904ms/step - loss: 0.2454 - accuracy: 0.9146 - val_loss: 0.3772 - val_accuracy: 0.8599
Epoch 4/200
107/107 [==============================] - 97s 903ms/step - loss: 0.2423 - accuracy: 0.9149 - val_loss: 0.3949 - val_accuracy: 0.8521
Epoch 5/200
107/107 [==============================] - 97s 903ms/step - loss: 0.2284 - accuracy: 0.9205 - val_loss: 0.4151 - val_accuracy: 0.8638
Epoch 6/200
107/107 [==============================] - 97s 906ms/step - loss: 0.2285 - accuracy: 0.9185 - val_loss: 0.4512 - val_accuracy: 0.8307
Epoch 7/200
107/107 [==============================] - 97s 904ms/step - loss: 0.2149 - accuracy: 0.9246 - val_loss: 0.3997 - val_accuracy: 0.8541
Epoch 8/200
107/107 [==============================] - 97s 903ms/step - loss: 0.2157 - accuracy: 0.9249 - val_loss: 0.4033 - val_accuracy: 0.8541
add Codeadd Markdown
Model Results
add Codeadd Markdown
The model is terminated after 49 epochs as it started overfitting.
The model is terminated by Early stopping.
The results are promising as the training accuracy is 93% while validation accuracy is 91.8%.
add Codeadd Markdown
#Plotting the model results
​
#Getting the accuracy
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
​
#Getting the losses
loss = history.history['loss']
val_loss = history.history['val_loss']
​
#No of epochs it trained
epochs_range = history.epoch
​
#Plotting Training and Validation accuracy
plt.figure(figsize=(16, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
​
#Plotting Training and Validation Loss
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

add Codeadd Markdown
Evaluation on Test Data
add Codeadd Markdown
#Loading the test data using Image Data Generator
test_gen = datagen.flow_from_directory("../Cancer_test/", target_size=(128,128), class_mode="binary", batch_size=1, shuffle=False)
Found 571 images belonging to 2 classes.
add Codeadd Markdown
pred = cancer_model.evaluate(test_gen)
571/571 [==============================] - 16s 27ms/step - loss: 0.4097 - accuracy: 0.8476
add Codeadd Markdown
Our CNN model is 91.5% accurate in predicting the cancer using the histopathology Images.
add Codeadd Markdown
#Let's Go ahead and test our model for few Images.
​
#Array to hold Input Images and their labels
test = []
labels = []
​
#Loading random 10 images
random_images = np.random.choice(data_test.index,10)
​
#For loop to read and store images
for i in random_images:
    #Finding their class to load from folder
    label = data_test.loc[i,"class"]
    labels.append(label)
    if label == 1:
        lab = "malignant"
    else:
        lab = "benign"
    #Creating path
    path = os.path.join("../Cancer_test/", lab, i)
    #reading image
    img = cv2.imread(path)
    #resizing to target shape
    img = cv2.resize(img,(128,128))
    #Making it an numpy array
    img = np.array(img)
    #Appending it to the list
    test.append(img)
​
#Making the list as numpy array
test = np.asarray(test)
#rescaling it by pixel value
test = test/255.   
add Codeadd Markdown
#Performing the prediction
pred = (cancer_model.predict(test) > 0.5).astype("int32")
#Flattening the list to form single dimensional list
pred = pred.flatten()
add Codeadd Markdown
#Plotting results and actual prediction
plt.figure(figsize=(20,10))
plt.suptitle("Prediction Vs Actual Result")
for i in range(0,10):
    string = "Actual:" + str(labels[i]) + ", Predicted:" + str(pred[i])
    plt.subplot(2,5,i+1)
    plt.imshow(test[i])
    plt.title(string)
